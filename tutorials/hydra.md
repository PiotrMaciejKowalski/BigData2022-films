Tutorial: Hydra dla projekt贸w Data Science
=======================================================

Celem tego poradnika jest kr贸tkie wprowadzenie do narzdzia Hydra. Om贸wiono w nim podstawowe operacje bazujc na materiale [Configuration Management For Data Science Made Easy With Hydra](https://www.youtube.com/watch?v=tEsPyYnzt8s).

>  Kod dla tego tutoriala jest dostpny na repozytorium GitHub: [https://github.com/ArjanCodes/2021-config](https://github.com/ArjanCodes/2021-config).

Instalacja i przegld
------------------------------------------------------

Bdziemy korzysta z wersji 1.3 (stable) biblioteki Hydra, kt贸r mo偶na zainstalowa poprzez:
```
pip install hydra-core --upgrade
```

Wprowadzenie
------------------------------------------------------
> "Hydra jest to framework typu open-source, kt贸ry upraszcza rozw贸j bada i innych zo偶onych aplikacji. Kluczow cech jest mo偶liwo dynamicznego tworzenia hierarchicznej konfiguracji przez kompozycj i nadpisywania jej poprzez pliki konfiguracyjne i lini polece. Nazwa Hydra pochodzi od jej zdolnoci do uruchamiania wielu podobnych zada - bardzo podobnie jak Hydra z wieloma gowami." [hydra.cc/docs/intro/](https://hydra.cc/docs/intro/)

**<font size = "5"><center>Przykad struktury Hydry dla modelu CNN</center></font>**

![Alt text](hydra_files/hydra.jpg)

Po lewej stronie mamy szereg plik贸w konfiguracyjnych, opisujcych kolejno:

1.  Konfiguracja dla zbioru danych;
2.  Konfiguracja naszej wstpnie wytrenowanej sieci;
3.  Konfiguracja naszego klasyfikatora wytrenowanego "na szczycie" sieci wstpnie wytrenowanej.

W centrum, Hydra automatycznie aduje i komponuje nasze pliki konfiguracyjne, dynamicznie nadpisujc ka偶d warto, kt贸r za偶damy w czasie pracy. 

Po prawej stronie, nasz skrypt treningowy wykorzystuje wynikowy obiekt sownikowy do budowy naszego modelu.

> 锔 Uwaga: Bdziemy usprawnia gotowy projekt dla modelu [LinearNet()](https://github.com/ArjanCodes/2021-config/tree/main/before).

main.py
------------------------------------------------------
Plik `main.py` bdzie plikiem, kt贸ry z wykrzystaniem bilbioteki `torch` oraz modu贸w z wewntrz projektu:
- buduje model klasyfikacyjny typu LinearNet(),
- aduje dane (zbi贸r MNIST),
- przeprowadza wielokrotne uczenie modelu,
- wywietla urednione metryki.
```
# import zewntrznych bibliotek
import pathlib
import torch

# import modu贸w z wewntrz projektu
from ds.dataset import create_dataloader
from ds.models import LinearNet
from ds.runner import Runner, run_epoch
from ds.tracking import TensorboardExperiment

# Hiperparametry dla modelu
EPOCH_COUNT = 20
LR = 5e-5
BATCH_SIZE = 128
LOG_PATH = "./runs"

# cie偶ki do danych
DATA_DIR = "../data/raw"
TEST_DATA = pathlib.Path(f"{DATA_DIR}/t10k-images-idx3-ubyte.gz")
TEST_LABELS = pathlib.Path(f"{DATA_DIR}/t10k-labels-idx1-ubyte.gz")
TRAIN_DATA = pathlib.Path(f"{DATA_DIR}/train-images-idx3-ubyte.gz")
TRAIN_LABELS = pathlib.Path(f"{DATA_DIR}/train-labels-idx1-ubyte.gz")

# aplikacja uruchamiajca ca procedur modelu (zaadowanie danych -> uczenie modelu -> wywietlenie metryk)
def main():

    # Model + optymalizator
    model = LinearNet()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # customowa funkcja adowania danych MNIST
    test_loader = create_dataloader(BATCH_SIZE, TEST_DATA, TEST_LABELS)
    train_loader = create_dataloader(BATCH_SIZE, TRAIN_DATA, TRAIN_LABELS)

    # customowa funkcja "dopasowujca" model do danych
    test_runner = Runner(test_loader, model)
    train_runner = Runner(train_loader, model, optimizer)

    # customowa funkcja ledzenia wynik贸w modelu
    tracker = TensorboardExperiment(log_path=LOG_PATH)

    # iteracyjne uczenie modelu (ze wzgldu na zadany parametr EPOCH_COUNT)
    for epoch_id in range(EPOCH_COUNT):
        # customowa funkcja uruchamiajca uczenie modelu
        run_epoch(test_runner, train_runner, tracker, epoch_id)

        # wyliczanie urednionych metryk z wykonanych epok
        summary = ", ".join(
            [
                f"[Epoch: {epoch_id + 1}/{EPOCH_COUNT}]",
                f"Test Accuracy: {test_runner.avg_accuracy: 0.4f}",
                f"Train Accuracy: {train_runner.avg_accuracy: 0.4f}",
            ]
        )
        print("\n" + summary + "\n")

        # Reset the runners
        train_runner.reset()
        test_runner.reset()

        # Flush the tracker after every epoch for live updates
        tracker.flush()


if __name__ == "__main__":
    main()
```

Pierwsze co mo偶emy dostrzec, jest zbdno plik贸w konfiguracyjnych. W celu wyczyszczenia `main.py`, przeniesiemy nasze hiperparametry oraz cie偶ki do oddzielnego pliku typu `.yaml`.

config.yaml
------------------------------------------------------
Najlepsz praktyk jest utworzenie dodatkowego folderu konfiguracyjnego w projekcie, przechowujcego wszystkie pliki konfiguracyjne. Plik konfiguracyjny `config.yaml` dla naszego projektu bdzie wyglda nastpujco:
```
# config.yaml
params:
    epoch_count: 20
    lr: 5e-5
    batch_size: 128
``` 
Tym sposobem, utworzylimy plik konfiguracyjny z grup o nazwie `params` oraz z zadanymi dla tej grupy trzema wartociami.
> Nale偶y pamita, aby wszelkie wartoci w pliku konfiguracyjnym zapisywa **maymi literami!**

Musimy r贸wnie偶 wstpnie przygootwa `main.py`.
```
# import zewntrznych bibliotek
import pathlib
import torch

import hydra # IMPORTOWANIE BIBLIOTEKI HYDRA

# import modu贸w z wewntrz projektu
from ds.dataset import create_dataloader
from ds.models import LinearNet
from ds.runner import Runner, run_epoch
from ds.tracking import TensorboardExperiment

# Hiperparametry dla modelu
EPOCH_COUNT = 20
LR = 5e-5
BATCH_SIZE = 128
LOG_PATH = "./runs"

# cie偶ki do danych
DATA_DIR = "../data/raw"
TEST_DATA = pathlib.Path(f"{DATA_DIR}/t10k-images-idx3-ubyte.gz")
TEST_LABELS = pathlib.Path(f"{DATA_DIR}/t10k-labels-idx1-ubyte.gz")
TRAIN_DATA = pathlib.Path(f"{DATA_DIR}/train-images-idx3-ubyte.gz")
TRAIN_LABELS = pathlib.Path(f"{DATA_DIR}/train-labels-idx1-ubyte.gz")

# aplikacja uruchamiajca ca procedur modelu (zaadowanie danych -> uczenie modelu -> wywietlenie metryk)
@hydra.main(config_path="conf", config_name="config") # WYKORZYSTANIE DEKORATORA, ABY WSKAZA MIEJSCE POO呕ENIA PLIKU KONFIGURACYJNEGO (config_path) ORAZ JEGO NAZWY (config_name)
def main(cfg):

    # Model + optymalizator
    model = LinearNet()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # customowa funkcja adowania danych MNIST
    test_loader = create_dataloader(BATCH_SIZE, TEST_DATA, TEST_LABELS)
    train_loader = create_dataloader(BATCH_SIZE, TRAIN_DATA, TRAIN_LABELS)

    # customowa funkcja "dopasowujca" model do danych
    test_runner = Runner(test_loader, model)
    train_runner = Runner(train_loader, model, optimizer)

    # customowa funkcja ledzenia wynik贸w modelu
    tracker = TensorboardExperiment(log_path=LOG_PATH)

    # iteracyjne uczenie modelu (ze wzgldu na zadany parametr EPOCH_COUNT)
    for epoch_id in range(EPOCH_COUNT):
        # customowa funkcja uruchamiajca uczenie modelu
        run_epoch(test_runner, train_runner, tracker, epoch_id)

        # wyliczanie urednionych metryk z wykonanych epok
        summary = ", ".join(
            [
                f"[Epoch: {epoch_id + 1}/{EPOCH_COUNT}]",
                f"Test Accuracy: {test_runner.avg_accuracy: 0.4f}",
                f"Train Accuracy: {train_runner.avg_accuracy: 0.4f}",
            ]
        )
        print("\n" + summary + "\n")

        # Reset the runners
        train_runner.reset()
        test_runner.reset()

        # Flush the tracker after every epoch for live updates
        tracker.flush()


if __name__ == "__main__":
    main()
```
Jak widzimy, pojawi si parametr `cfg`, kt贸ry oznacza, 偶e Hydra automatycznie wprowadzi parametry z pliku `config.yaml` do funkcji `main()`.

Dodajmy r贸wnie偶 pliki do pliku konfiguracyjnego. W tym celu dodamy kolejn grup `files`.

```
# config.yaml
files:
    test_data: t10k-images-idx3-ubyte.gz
    test_labels: t10k-labels-idx1-ubyte.gz
    train_data: train-images-idx3-ubyte.gz
    train_labels: train-labels-idx1-ubyte.gz
params:
    epoch_count: 20
    lr: 5e-5
    batch_size: 128
``` 

Zauwa偶my, 偶e cie偶ki r贸wnie偶 warto trzyma w pliku konfiguracyjnym, poniewa偶 da nam to lepsz kontrol nad struktur projektu, tj.:

```
# config.yaml
files:
    test_data: t10k-images-idx3-ubyte.gz
    test_labels: t10k-labels-idx1-ubyte.gz
    train_data: train-images-idx3-ubyte.gz
    train_labels: train-labels-idx1-ubyte.gz
paths:
    log: ./runs
    data: ../data/raw
params:
    epoch_count: 20
    lr: 5e-5
    batch_size: 128
``` 

> Usunicie cudzysow贸w ze cie偶ek jest zwizane z plikami typu `.yaml`, poniewa偶 nie maj one potrzeby ich u偶ywania.

Uwaga. Nale偶y zabezpieczy nasz plik konfiguracyjny przed nieprawdiowym wskazaniem cie偶ki. W tym celu wykorzstamy hydr i zawrzemy w cie偶ce do danych  informacj o katalogu bie偶cym.

```
# config.yaml
files:
    test_data: t10k-images-idx3-ubyte.gz
    test_labels: t10k-labels-idx1-ubyte.gz
    train_data: train-images-idx3-ubyte.gz
    train_labels: train-labels-idx1-ubyte.gz
paths:
    log: ./runs
    data: ${hydra:runtime.cwd}/../data/raw
params:
    epoch_count: 20
    lr: 5e-5
    batch_size: 128
``` 

Tym sposobem, nasza cie偶ka do danych, wychodzi z katalogu bie偶cego do wskazanego.

Jak to widzi Hydra? Po "wyprintowaniu" pliku konfiguracyjnego:
```
import hydra

@hydra.main(config_path="conf", config_name="config")
def main(cfg):
    print(cfg)
    return

if __name__ == "__main__":
    main()
```

ukazuje si nam sownik z parametrami:

```
{
    "files": {
        "test_data": "t10k-images-idx3-ubyte.gz",
        "test_labels": "t10k-labels-idx1-ubyte.gz",
        "train_data": "train-images-idx3-ubyte.gz",
        "train_labels": "train-labels-idx1-ubyte.gz",
    },
    "paths": {"log": "./runs", "data": "../data/raw"},
    "params": {"epoch_count": 20, "lr": 5e-05, "batch_size": 128},
}
```

Dodatkowo, hydra ka偶drowazowo zapisuje plik konfiguracyjny w folderze output, kt贸ry tworzony jest automatycznie, co pozwala nam ledzi wszelkie modyfikacje.

![Alt text](hydra_files/outputs.png)

Tym sposobem, otrzymalimy podstawowy plik konfiguracyjny zawierajcy wszystkie parametry/dane/cie偶ki.

Wprowad藕my je do `main.py`:

```
import hydra  # IMPORTOWANIE BIBLIOTEKI HYDRA

# import modu贸w z wewntrz projektu
from ds.dataset import create_dataloader
from ds.models import LinearNet
from ds.runner import Runner, run_epoch
from ds.tracking import TensorboardExperiment

@hydra.main(config_path="conf", config_name="config")
def main(cfg):

    # Model + optymalizator
    model = LinearNet()
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.params.lr)

    # customowa funkcja adowania danych MNIST
    test_loader = create_dataloader(
        cfg.params.batch_size,
        pathlib.Path(f"{cfg.paths.data}/{cfg.files.test_data}"),
        pathlib.Path(f"{cfg.paths.data}/{cfg.files.test_labels}"),
    )
    train_loader = create_dataloader(
        cfg.params.batch_size,
        pathlib.Path(f"{cfg.paths.data}/{cfg.files.train_data}"),
        pathlib.Path(f"{cfg.paths.data}/{cfg.files.train_labels}"),
    )

    # customowa funkcja "dopasowujca" model do danych
    test_runner = Runner(test_loader, model)
    train_runner = Runner(train_loader, model, optimizer)

    # customowa funkcja ledzenia wynik贸w modelu
    tracker = TensorboardExperiment(log_path=cfg.paths.log)

    # iteracyjne uczenie modelu (ze wzgldu na zadany parametr EPOCH_COUNT)
    for epoch_id in range(cfg.params.epoch_count):
        # customowa funkcja uruchamiajca uczenie modelu
        run_epoch(test_runner, train_runner, tracker, epoch_id)

        # wyliczanie urednionych metryk z wykonanych epok
        summary = ", ".join(
            [
                f"[Epoch: {epoch_id + 1}/{cfg.params.epoch_count}]",
                f"Test Accuracy: {test_runner.avg_accuracy: 0.4f}",
                f"Train Accuracy: {train_runner.avg_accuracy: 0.4f}",
            ]
        )
        print("\n" + summary + "\n")

        # Reset the runners
        train_runner.reset()
        test_runner.reset()

        # Flush the tracker after every epoch for live updates
        tracker.flush()


if __name__ == "__main__":
    main()
```

----
Podsumowujc, udao nam si przenie parametry do jednego pliku konfiguracyjnego, co pozwolio na zwikszenie przejrzystoci g贸wnego skryptu oraz, co najwa偶niejsze, pozwala na kontrolowanie parametr贸w modelu/cie偶ek/藕r贸de danych dla caego projektu.

Mimo, 偶e wykorzystalimy tylko fundamentalne reguy pakietu `Hydra`, a ju偶 to pozwalio nam na ledzenie pracy nad projektem poprzez zapis konfiguracji w folderze `outputs`, co jest ogromn zalet.


