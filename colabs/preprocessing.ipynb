{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrMaciejKowalski/BigData2022-films/blob/Preprocessing-danych/colabs/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Agowe5uPVKS"
      },
      "source": [
        "# Spark Setup and Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xea8rmW1Mtc8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8My8u33PYJt"
      },
      "outputs": [],
      "source": [
        "# install Java8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# download spark2.4.5\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "# unzip it\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "# install findspark\n",
        "!pip install -q findspark\n",
        "# clone github repo\n",
        "!git clone https://github.com/PiotrMaciejKowalski/BigData2022-films\n",
        "# Przeniesienie plików z BigData2022-films do katalogu nadrzędnego\n",
        "!mv BigData2022-films/* .\n",
        "!mv BigData2022-films/.* .\n",
        "!rmdir BigData2022-films"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fG3Xpjc4MvYY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# setup environment variables for our Spark Session to work\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.2.1-bin-hadoop3.2'\n",
        "\n",
        "from lib.pyspark_startup import init, load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lIJChpFeBN-U"
      },
      "outputs": [],
      "source": [
        "spark = init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fOLm43gvBWNM"
      },
      "outputs": [],
      "source": [
        "# Ładowanie danych z dysku google\n",
        "path = \"/content/drive/.shortcut-targets-by-id/1VcOir9FMG8LzEsUE-Q8YA79c_sV0tJwp/bigdata2022/\"\n",
        "\n",
        "df = spark.read.parquet(path + \"clean_df.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "yXU7xq4qUiNk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnOuFwAFUj4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Podział na zbiór uczący, walidacyjny i testowy"
      ],
      "metadata": {
        "id": "Vl0Y0n5XTPDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, valid, test = df.randomSplit([0.70, 0.2, 0.1], seed=123)"
      ],
      "metadata": {
        "id": "9lZQjmV_TOgj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3naR3zhLJDPH"
      },
      "source": [
        "# Zapis na dysku"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL93JLOGJF0Y"
      },
      "outputs": [],
      "source": [
        "train.write.mode(\"overwrite\").parquet(path + \"train_df.parquet\")\n",
        "valid.write.mode(\"overwrite\").parquet(path + \"valid_df.parquet\")\n",
        "test.write.mode(\"overwrite\").parquet(path + \"test_df.parquet\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('bigdata2022_env')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3bd7558b382e9dfedbadb497b519832d5eeed5cdea53be5faf7c2ce6e68cd89"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}